# ----------------------------------------
# ğŸ“Œ ä½¿ç”¨èªªæ˜ï¼ˆUsageï¼‰
#
# 1. åœ¨ä¸Šä¸€å±¤è³‡æ–™å¤¾æº–å‚™ `.env.local`ï¼š
#    YOUTUBE_API_KEY=ä½ çš„APIé‡‘é‘°
#
# 2. å°‡è¦è§£æçš„ YouTube é »é“ç¶²å€æ¸…å–®ï¼Œæ”¾å…¥æœ¬è³‡æ–™å¤¾çš„ `channel_list_handle.txt`ï¼Œä¸€è¡Œä¸€å€‹ã€‚
#
# 3. åŸ·è¡Œæ­¤è…³æœ¬å¾Œï¼Œæœƒï¼š
#    - å°‡ UC é–‹é ­çš„ channel ID å¯«å…¥ `channel_list.txt`ï¼ˆä¸€è¡Œä¸€ç­†ï¼Œappendï¼‰
#    - å¿«å– handle â†” channelId åˆ° `handle_cache.json`
# ----------------------------------------
# åŸ·è¡Œè…³æœ¬
# python resolve_channel_id.py

import os
import re
import json
import requests
from dotenv import load_dotenv

# âœ… è¼‰å…¥ API é‡‘é‘°
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), '../.env.local'))
API_KEY = os.getenv("API_KEY")

# âœ… æª”æ¡ˆèˆ‡å¿«å–è·¯å¾‘
CACHE_FILE = "handle_cache.json"
OUTPUT_FILE = "channel_list.txt"
INPUT_FILE = "channel_list_handle.txt"

# âœ… è¼‰å…¥å¿«å–ï¼ˆè‹¥ç„¡å‰‡åˆå§‹åŒ–ï¼‰
if os.path.exists(CACHE_FILE):
    with open(CACHE_FILE, "r", encoding="utf-8") as f:
        handle_cache = json.load(f)
else:
    handle_cache = {}

def extract_channel_id(url: str) -> str | None:
    """
    æ“·å– UC channelIdï¼Œå¦‚æœæ˜¯ @handle æœƒæŸ¥ APIã€‚
    """
    url = url.strip()

    # 1. æ˜¯ UC æ ¼å¼
    match = re.match(r'^https?://(www\.)?youtube\.com/channel/(UC[\w-]+)', url)
    if match:
        return match.group(2)

    # 2. æ˜¯ @handle æ ¼å¼
    match = re.match(r'^https?://(www\.)?youtube\.com/@([\w\-.]+)', url)
    if match:
        handle = "@" + match.group(2)

        # æŸ¥å¿«å–
        if handle in handle_cache:
            print(f"âœ… å¿«å–å‘½ä¸­ï¼š{handle} â†’ {handle_cache[handle]}")
            return handle_cache[handle]

        # æŸ¥ API
        print(f"ğŸŒ æ­£åœ¨æŸ¥è©¢ APIï¼š{handle}")
        try:
            response = requests.get(
                "https://www.googleapis.com/youtube/v3/channels",
                params={
                    "part": "id",
                    "forHandle": handle,
                    "key": API_KEY
                },
                timeout=10
            )
            response.raise_for_status()
            data = response.json()
            if data["items"]:
                channel_id = data["items"][0]["id"]
                handle_cache[handle] = channel_id
                # æ›´æ–°å¿«å–
                with open(CACHE_FILE, "w", encoding="utf-8") as f:
                    json.dump(handle_cache, f, ensure_ascii=False, indent=2)
                print(f"âœ… æŸ¥è©¢æˆåŠŸï¼š{handle} â†’ {channel_id}")
                return channel_id
            else:
                print(f"âŒ æ‰¾ä¸åˆ°é »é“ï¼š{handle}")
        except Exception as e:
            print(f"âŒ API éŒ¯èª¤ï¼š{e}")
        return None

    # 3. ä¸æ”¯æ´æ ¼å¼
    print(f"âš ï¸ ç•¥éä¸æ”¯æ´æ ¼å¼ï¼š{url}")
    return None

# âœ… è®€å–ç¶²å€æ¸…å–®ä¸¦è™•ç†
if not os.path.exists(INPUT_FILE):
    print(f"âŒ æ‰¾ä¸åˆ°è¼¸å…¥æª”æ¡ˆï¼š{INPUT_FILE}")
    exit(1)

with open(INPUT_FILE, "r", encoding="utf-8") as f:
    urls = [line.strip() for line in f if line.strip()]

print(f"ğŸ” å…±è®€å– {len(urls)} ç­†ç¶²å€ï¼Œé–‹å§‹è™•ç†...\n")

success_count = 0
with open(OUTPUT_FILE, "a", encoding="utf-8") as out_f:
    for url in urls:
        channel_id = extract_channel_id(url)
        if channel_id:
            out_f.write(channel_id + "\n")
            success_count += 1

print(f"\nâœ… å®Œæˆè™•ç†ï¼Œå…±å¯«å…¥ {success_count} ç­† channel ID åˆ° {OUTPUT_FILE}")
