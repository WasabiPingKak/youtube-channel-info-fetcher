from datetime import datetime, timezone
import logging
import json

def is_channel_heatmap_initialized(db, channel_id: str) -> bool:
    """
    æª¢æŸ¥é »é“ heat_map æ˜¯å¦å·²åˆå§‹åŒ–ï¼ˆå³æ˜¯å¦å«æœ‰ all_range æ¬„ä½ï¼‰

    åƒæ•¸:
        db: Firestore client å¯¦é«”
        channel_id: é »é“ ID

    å›å‚³:
        True è¡¨ç¤ºå·²åˆå§‹åŒ–ï¼ˆå·²å­˜åœ¨ all_range æ¬„ä½ï¼‰
        False è¡¨ç¤ºæœªåˆå§‹åŒ–æˆ–è®€å–å¤±æ•—
    """
    try:
        doc_ref = db.document(f"channel_data/{channel_id}/heat_map/channel_video_heatmap")
        doc = doc_ref.get()
        if doc.exists:
            is_initialized = "all_range" in doc.to_dict()
            if not is_initialized:
                logging.info(f"ğŸ†• é »é“ {channel_id} å°šæœªåˆå§‹åŒ– heatmapï¼ˆç„¡ all_rangeï¼‰")
            return is_initialized
        else:
            logging.info(f"ğŸ†• é »é“ {channel_id} heatmap æ–‡ä»¶ä¸å­˜åœ¨ï¼ˆå°šæœªåˆå§‹åŒ–ï¼‰")
            return False
    except Exception as e:
        logging.error(f"â— æª¢æŸ¥ heatmap åˆå§‹åŒ–ç‹€æ…‹å¤±æ•—ï¼š{channel_id} - {e}")
        return False

def convert_to_nested_map(matrix):
    """
    å°‡ matrix ç”± map<string, list<list<string>>> è½‰ç‚º map<string, map<string, list<string>>>
    Firestore ä¸æ¥å— array of arrayï¼Œä½†æ¥å— map of map
    """
    return {
        day: {str(hour): hour_list for hour, hour_list in enumerate(hour_lists)}
        for day, hour_lists in matrix.items()
    }

def write_channel_heatmap_result(
    db,
    channel_id,
    full_matrix=None,
    full_count=None,
    slot_counter=None  # ä»ä¿ç•™æ­¤åƒæ•¸ä¾›å…¶ä»–æ¨¡çµ„ä½¿ç”¨ï¼ˆä½†æœ¬å‡½å¼ä¸­ä¸è™•ç†ï¼‰
):
    try:
        # å°‡ path ä¿®æ­£ç‚ºåˆæ³•çš„ 4 æ®µï¼ˆcollection/document/collection/documentï¼‰
        doc_ref = db.document(f"channel_data/{channel_id}/heat_map/channel_video_heatmap")
        update_data = {}
        now = datetime.now(timezone.utc)

        if full_matrix is not None and full_count is not None:
            update_data = {
                "all_range": {  # âœ… æ”¹ç‚ºæ¬„ä½ keyï¼Œè€Œé Firestore path
                    "matrix": convert_to_nested_map(full_matrix),
                    "totalCount": full_count,
                    "updatedAt": now
                }
            }
            logging.debug(f"ğŸ“¦ æº–å‚™å¯«å…¥ all_rangeï¼šå½±ç‰‡æ•¸={full_count}")

        if not update_data:
            logging.warning(f"âš ï¸ æ²’æœ‰è³‡æ–™éœ€è¦å¯«å…¥ï¼š{channel_id}")
            return

        # å°å‡ºå¯«å…¥å‰çš„å…§å®¹ï¼ˆè½‰å­—ä¸²ä»¥é¿å… datetime ç„¡æ³•åºåˆ—åŒ–ï¼‰
        serialized = {
            k: (
                {sub_k: (str(sub_v) if isinstance(sub_v, datetime) else sub_v)
                 for sub_k, sub_v in v.items()}
                if isinstance(v, dict) else v
            )
            for k, v in update_data.items()
        }
        logging.debug(f"ğŸ“¤ å¯«å…¥å‰è³‡æ–™å…§å®¹ï¼ˆ{channel_id}ï¼‰ï¼š\n{json.dumps(serialized, ensure_ascii=False, indent=2)}")

        # è¦†è“‹å¯«å…¥æ•´å€‹ document
        doc_ref.set(update_data)
        logging.info(f"âœ… å¯«å…¥æˆåŠŸï¼š{channel_id}ï¼ˆæ¬„ä½æ•¸ï¼š{len(update_data)}ï¼‰")

    except Exception as e:
        logging.error(f"ğŸ”¥ å¯«å…¥ {channel_id} çµ±è¨ˆè³‡æ–™å¤±æ•—ï¼š{e}")
