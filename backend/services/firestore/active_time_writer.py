from datetime import datetime
import logging

def write_active_time_all_to_channel_index_batch(
    db,
    channel_id: str,
    slot_counter: list[int],  # [å‡Œ, æ—©, åˆ, æ™š]
    total_count: int,
    updated_at: datetime
):
    try:
        # å¾ batch_0 é–‹å§‹æƒææ‰€æœ‰ batch æ–‡ä»¶
        batch_prefix = "channel_index_batch"
        batch_ids = [doc.id for doc in db.collection(batch_prefix).stream() if doc.id.startswith("batch_")]
        batch_ids.sort()  # ä¿è­‰é †åºæƒæï¼ˆé›–ç„¶é †åºä¸å½±éŸ¿ï¼‰

        for batch_id in batch_ids:
            doc_ref = db.collection(batch_prefix).document(batch_id)
            doc = doc_ref.get()
            if not doc.exists:
                continue

            data = doc.to_dict()
            channels = data.get("channels", [])
            for i, ch in enumerate(channels):
                if ch.get("channel_id") == channel_id:
                    # æº–å‚™æ–°çš„ active_time_all æ¬„ä½
                    new_stat = {
                        "å‡Œ": slot_counter[0],
                        "æ—©": slot_counter[1],
                        "åˆ": slot_counter[2],
                        "æ™š": slot_counter[3],
                        "totalCount": total_count,
                        "updatedAt": updated_at
                    }

                    channels[i]["active_time_all"] = new_stat

                    # å¯«å›æ•´å€‹ channels é™£åˆ—
                    doc_ref.set({
                        "channels": channels,
                    }, merge=True)

                    logging.info(f"ğŸ“ æˆåŠŸå¯«å…¥ active_time_all â†’ {channel_id}ï¼ˆä½æ–¼ {batch_id}, index={i}ï¼‰")
                    return

        logging.warning(f"â— æ‰¾ä¸åˆ°ç¬¦åˆçš„ channel_idï¼š{channel_id}ï¼Œç„¡æ³•å¯«å…¥ active_time_all")

    except Exception as e:
        logging.error(f"ğŸ”¥ å¯«å…¥ active_time_all å¤±æ•—ï¼ˆ{channel_id}ï¼‰ï¼š{e}")
