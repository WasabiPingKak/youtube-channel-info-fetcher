import logging
import os
import requests
from flask import Blueprint, request, jsonify
from google.cloud.firestore import Client
from datetime import datetime, timedelta, timezone

live_redirect_bp = Blueprint("live_redirect", __name__)
YOUTUBE_API_KEY = os.getenv("API_KEY")
CACHE_DOC_PATH = ("live_redirect_cache", "current")
QUEUE_DOC_PATH = ("live_redirect_notify_queue", "current")
CHANNEL_INDEX_COLLECTION = "channel_index"
YOUTUBE_API = "https://www.googleapis.com/youtube/v3/videos"


def build_live_redirect_cache_entries(videos: list, db: Client, now: datetime):
    output_channels = []
    processed_video_ids = []

    for video in videos:
        video_id = video.get("videoId")
        channel_id = video.get("channelId")
        if not video_id or not channel_id:
            continue

        logging.info(f"ğŸ” æŸ¥è©¢å½±ç‰‡ï¼š{video_id}")

        # å‘¼å« YouTube API
        params = {
            "part": "snippet,liveStreamingDetails",
            "id": video_id,
            "key": YOUTUBE_API_KEY
        }
        yt_resp = requests.get(YOUTUBE_API, params=params)
        if yt_resp.status_code != 200:
            logging.warning(f"âš ï¸ YouTube API éŒ¯èª¤ï¼š{video_id} - {yt_resp.status_code}")
            continue

        items = yt_resp.json().get("items", [])
        if not items:
            continue

        item = items[0]
        snippet = item.get("snippet", {})
        live_details = item.get("liveStreamingDetails", {})

        if not live_details:
            logging.info(f"ğŸŸ¡ ä¸æ˜¯ç›´æ’­å½±ç‰‡ï¼Œç•¥éä½†æ¨™è¨˜ç‚ºå·²è™•ç†ï¼š{channel_id} / {video_id}")
            processed_video_ids.append(video_id)
            continue

        actual_start = live_details.get("actualStartTime")
        scheduled_start = live_details.get("scheduledStartTime")
        actual_end = live_details.get("actualEndTime")
        viewers = int(live_details.get("concurrentViewers", "0"))

        is_live = False
        is_upcoming = False
        start_time = None

        if actual_end:
            start_time = actual_start or scheduled_start
        else:
            if actual_start and datetime.fromisoformat(actual_start) <= now:
                is_live = True
                is_upcoming = False
                start_time = actual_start
            elif scheduled_start and datetime.fromisoformat(scheduled_start) <= now + timedelta(minutes=15):
                is_live = True
                is_upcoming = True
                start_time = scheduled_start

        logging.debug(
            f"ğŸ§ª åˆ¤æ–·å½±ç‰‡ç‹€æ…‹ - channel: {channel_id} / video: {video_id}\n"
            f"  actualStartTime: {actual_start}\n"
            f"  scheduledStartTime: {scheduled_start}\n"
            f"  actualEndTime: {actual_end}\n"
            f"  viewers: {viewers}\n"
            f"  â†’ åˆ¤å®šçµæœ: is_live={is_live}, is_upcoming={is_upcoming}, start_time={start_time}"
        )

        if not is_live and not actual_end:
            continue

        # å–å¾—é »é“è³‡æ–™
        channel_doc = db.collection(CHANNEL_INDEX_COLLECTION).document(channel_id).get()
        if not channel_doc.exists:
            logging.warning(f"â—æ‰¾ä¸åˆ°é »é“è³‡æ–™ï¼š{channel_id}")
            continue
        channel_data = channel_doc.to_dict()

        output_channels.append({
            "channel_id": channel_id,
            "name": channel_data.get("name"),
            "thumbnail": channel_data.get("thumbnail"),
            "badge": channel_data.get("badge"),
            "countryCode": channel_data.get("countryCode", []),
            "live": {
                "videoId": video_id,
                "title": snippet.get("title"),
                "startTime": start_time,
                "viewers": viewers,
                "isUpcoming": is_upcoming,
                "endTime": actual_end
            }
        })

        logging.info(f"âœ… ç´å…¥å¿«å–ï¼š{channel_id} / {video_id}")
        processed_video_ids.append(video_id)

    return output_channels, processed_video_ids


def init_live_redirect_route(app, db: Client):
    @live_redirect_bp.route("/api/live-redirect/cache", methods=["GET"])
    def get_live_redirect_cache():
        try:
            force = request.args.get("force", "false").lower() == "true"
            now = datetime.now(timezone.utc)

            # è®€ä¸»å¿«å–
            cache_ref = db.collection(CACHE_DOC_PATH[0]).document(CACHE_DOC_PATH[1])
            cache_data = cache_ref.get().to_dict() or {}
            updated_at = cache_data.get("updatedAt")

            if not force and updated_at:
                updated_time = datetime.fromisoformat(updated_at)
                if now - updated_time < timedelta(minutes=5):
                    logging.info("â™»ï¸ å¿«å–æœªéæœŸï¼Œç›´æ¥å›å‚³")
                    return jsonify(cache_data)

            # è®€é€šçŸ¥ä½‡åˆ—
            queue_ref = db.collection(QUEUE_DOC_PATH[0]).document(QUEUE_DOC_PATH[1])
            queue_data = queue_ref.get().to_dict() or {}
            videos = queue_data.get("videos", [])

            # å‚™ä»½èˆŠå¿«å–è³‡æ–™ï¼ˆåƒ…é force æ¨¡å¼æ™‚åˆä½µï¼‰
            existing_channels = cache_data.get("channels", []) if not force else []
            existing_map = {c["live"]["videoId"]: c for c in existing_channels}

            # æ‰€æœ‰å½±ç‰‡ä¸€å¾‹é‡æ–°æŸ¥è©¢ï¼Œä½†æ˜¯å¦æ›´æ–° processedAt ç”± force æ§åˆ¶
            new_channels, processed_video_ids = build_live_redirect_cache_entries(videos, db, now)
            for c in new_channels:
                vid = c["live"]["videoId"]
                existing_map[vid] = c  # åˆä½µæ–°èˆŠå¿«å–

            merged_channels = list(existing_map.values())

            # å¯«å…¥å¿«å–
            cache_ref.set({
                "updatedAt": now.isoformat(),
                "channels": merged_channels
            })

            # æ›´æ–°ä½‡åˆ—çš„ processedAtï¼ˆåªæœ‰åœ¨ force æ™‚æ›´æ–°ï¼‰
            new_videos = []
            for v in videos:
                if v.get("videoId") in processed_video_ids:
                    if force or not v.get("processedAt"):
                        v["processedAt"] = now.isoformat()
                new_videos.append(v)

            queue_ref.set({
                "updatedAt": now.isoformat(),
                "videos": new_videos
            })

            logging.info(f"âœ… å¿«å–é‡å»ºå®Œæˆï¼Œchannels={len(merged_channels)}ï¼Œæ›´æ–°å½±ç‰‡={len(processed_video_ids)}")

            return jsonify({
                "updatedAt": now.isoformat(),
                "channels": merged_channels
            })

        except Exception:
            logging.exception("ğŸ”¥ å¿«å–é‡å»ºæµç¨‹å¤±æ•—")
            return jsonify({"error": "Internal Server Error"}), 500

    app.register_blueprint(live_redirect_bp)
