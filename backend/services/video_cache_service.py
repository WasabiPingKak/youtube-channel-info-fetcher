import logging
from datetime import datetime, timezone
from google.cloud import firestore
from services.youtube.fetcher import get_video_data
from utils.categorizer import match_category_and_game
from utils.youtube_utils import normalize_video_item
from dateutil.parser import parse

# âœ… æŠ½å‡ºé¡å‹æ˜ å°„è¡¨ï¼Œä¾›å¤šå€‹å‡½å¼å…±ç”¨
type_map = {
    "ç›´æ’­æª”": "live",
    "ç›´æ’­": "live",
    "å½±ç‰‡": "videos",
    "Shorts": "shorts",
    "shorts": "shorts"
}

def refresh_video_cache(db, channel_id: str, date_ranges=None):
    try:
        # å–å¾—è¨­å®šè³‡æ–™
        settings_ref = db.collection("channel_data").document(channel_id).collection("settings").document("config")
        settings_doc = settings_ref.get()
        if not settings_doc.exists:
            logging.warning("âš ï¸ [refresh_video_cache] ç„¡æ³•æ‰¾åˆ°åˆ†é¡è¨­å®š config")
            return []

        settings = settings_doc.to_dict()
        logging.debug(f"ğŸ› ï¸ [DEBUG] è®€åˆ°è¨­å®šæ¬„ä½ï¼š{list(settings.keys())}")

        raw_items = get_video_data(date_ranges=date_ranges, input_channel=channel_id)
        saved_videos = []

        for raw_item in raw_items:
            item = normalize_video_item(raw_item)
            if not item:
                continue  # æ­£è¦åŒ–å¤±æ•—çš„ç•¥é

            video_id = item.get("videoId")
            title = item.get("title")
            publish_date = item.get("publishDate")
            duration = item.get("duration")
            video_type = item.get("type")

            if not all([video_id, title, publish_date, video_type]):
                logging.warning("âš ï¸ [refresh_video_cache] ç•¥éè³‡æ–™ä¸å®Œæ•´å½±ç‰‡: %s", item)
                continue

            type_for_setting = type_map.get(video_type, video_type)

            # âœ… é™¤éŒ¯ç”¨ï¼šç¢ºèª video_type èˆ‡è¨­å®šå°æ‡‰æ˜¯å¦æ­£ç¢º
            logging.debug(f"ğŸï¸ [DEBUG] è™•ç†å½±ç‰‡é¡å‹: åŸå§‹={video_type}, æ˜ å°„å¾Œ={type_for_setting}")
            logging.debug(f"ğŸ§ª [DEBUG] è¨­å®šä¸­æ˜¯å¦å­˜åœ¨é¡å‹ '{type_for_setting}': {'âœ… å­˜åœ¨' if type_for_setting in settings else 'âŒ ä¸å­˜åœ¨'}")

            result = match_category_and_game(title, type_for_setting, settings)

            video_data = {
                "videoId": video_id,
                "title": title,
                "publishDate": publish_date,
                "duration": duration,
                "type": video_type,
                "matchedCategories": result["matchedCategories"],
                "game": result["game"],
                "matchedKeywords": result["matchedKeywords"]
            }

            video_ref = db.collection("channel_data").document(channel_id).collection("videos").document(video_id)
            video_ref.set(video_data)
            saved_videos.append(video_data)

        logging.info("âœ… [refresh_video_cache] å¯«å…¥å®Œæˆï¼Œå…± %d ç­†", len(saved_videos))
        return saved_videos

    except Exception as e:
        logging.error("ğŸ”¥ [refresh_video_cache] å¿«å–æ›´æ–°éŒ¯èª¤", exc_info=True)
        return []

def update_latest_videos(db, channel_id: str) -> dict:
    """
    å¢é‡åŒæ­¥æŒ‡å®šé »é“çš„æœ€æ–°å½±ç‰‡ï¼š
    - ä»¥ cache_meta.lastVideoSyncAt ä½œç‚ºç¯©é¸èµ·é»
    - æ–°å¢å½±ç‰‡å¾Œï¼Œå°‡ lastVideoSyncAt æ›´æ–°ç‚ºã€Œæœ€æ–°å½±ç‰‡çš„ publishDateï¼ˆISO å­—ä¸²ï¼ŒUTCï¼‰ã€
    """
    try:
        # å–å¾—åˆ†é¡è¨­å®š
        settings_ref = db.collection("channel_data").document(channel_id).collection("settings").document("config")
        settings_doc = settings_ref.get()
        if not settings_doc.exists:
            raise ValueError("æ‰¾ä¸åˆ°åˆ†é¡è¨­å®š config")
        settings = settings_doc.to_dict()

        # è®€å– cache_meta çš„ lastVideoSyncAt
        cache_meta_ref = db.collection("channel_data").document(channel_id).collection("channel_info").document("cache_meta")
        cache_meta_doc = cache_meta_ref.get()
        last_sync_time = None
        if cache_meta_doc.exists:
            raw_sync = cache_meta_doc.to_dict().get("lastVideoSyncAt")
            if raw_sync:
                # å¯èƒ½æ˜¯ ISO å­—ä¸²æˆ– Firestore Timestampï¼Œçµ±ä¸€è½‰æˆ timezone-aware datetime
                if isinstance(raw_sync, str):
                    last_sync_time = parse(raw_sync)
                else:  # Timestamp ç‰©ä»¶
                    try:
                        last_sync_time = raw_sync.to_datetime()
                    except AttributeError:
                        logging.warning("âš ï¸ [update_latest_videos] ç„¡æ³•è§£æ lastVideoSyncAt: %s", raw_sync)

        # è¨ˆç®—æ—¥æœŸç¯„åœï¼šå¾ last_sync_time åˆ°ç¾åœ¨ï¼ˆUTCï¼‰
        now_utc = datetime.now(timezone.utc)
        date_ranges = [(last_sync_time, now_utc)] if last_sync_time else None

        raw_items = get_video_data(date_ranges=date_ranges, input_channel=channel_id)
        logging.info(f"ğŸ” [update_latest_videos] æ’ˆå›å½±ç‰‡æ•¸é‡ï¼š{len(raw_items)}")

        added, skipped = 0, 0
        max_publish_time = None  # datetime ç‰©ä»¶

        for raw_item in raw_items:
            item = normalize_video_item(raw_item)
            if not item:
                continue

            video_id = item.get("videoId")
            title = item.get("title")
            publish_date_str = item.get("publishDate")  # ISO å­—ä¸²
            duration = item.get("duration")
            video_type = item.get("type")

            if not all([video_id, title, publish_date_str, video_type]):
                logging.warning("âš ï¸ [update_latest_videos] ç•¥éè³‡æ–™ä¸å®Œæ•´å½±ç‰‡: %s", item)
                continue

            # å°‡ publish_date å­—ä¸²è½‰ç‚º datetimeï¼ˆåªç”¨æ–¼æ¯”è¼ƒï¼‰
            try:
                publish_dt = parse(publish_date_str)
            except Exception:
                logging.warning("âš ï¸ [update_latest_videos] ç„¡æ³•è§£ææ—¥æœŸå­—ä¸²: %s", publish_date_str, exc_info=True)
                continue

            video_ref = db.collection("channel_data").document(channel_id).collection("videos").document(video_id)
            if video_ref.get().exists:
                skipped += 1
                continue

            type_for_setting = type_map.get(video_type, video_type)
            result = match_category_and_game(title, type_for_setting, settings)

            video_data = {
                "videoId": video_id,
                "title": title,
                "publishDate": publish_date_str,
                "duration": duration,
                "type": video_type,
                "matchedCategories": result["matchedCategories"],
                "game": result["game"],
                "matchedKeywords": result["matchedKeywords"]
            }

            video_ref.set(video_data)
            added += 1

            # æ›´æ–°æœ€æ–°ç™¼ä½ˆæ™‚é–“
            if not max_publish_time or publish_dt > max_publish_time:
                max_publish_time = publish_dt

        # è‹¥æœ‰æ–°å¢å½±ç‰‡ï¼Œæ›´æ–° cache_meta çš„ lastVideoSyncAt
        updated_time_str = None
        if added > 0 and max_publish_time:
            updated_time_str = max_publish_time.isoformat()
            cache_meta_ref.set({
                "lastVideoSyncAt": updated_time_str
            }, merge=True)

        logging.info(f"âœ… [update_latest_videos] æ–°å¢ {added} ç­†ï¼Œç•¥é {skipped} ç­†")
        return {
            "added": added,
            "skipped": skipped,
            "updatedSyncTime": updated_time_str
        }

    except Exception:
        logging.exception("ğŸ”¥ [update_latest_videos] åŒæ­¥å½±ç‰‡ç™¼ç”ŸéŒ¯èª¤")
        raise

def apply_category_settings_to_videos(db, channel_id: str, settings: dict) -> int:
    """
    å¥—ç”¨æœ€æ–°çš„åˆ†é¡è¨­å®šåˆ°æ‰€æœ‰å·²å­˜åœ¨çš„å½±ç‰‡ä¸Šï¼Œåƒ…æ›´æ–°åˆ†é¡æœ‰è®Šå‹•çš„å½±ç‰‡ï¼Œå›å‚³å¯¦éš›æ›´æ–°æ•¸é‡ã€‚
    """
    try:
        videos_ref = db.collection("channel_data").document(channel_id).collection("videos")
        video_docs = videos_ref.stream()

        updated_count = 0

        for doc in video_docs:
            video = doc.to_dict()
            video_id = video.get("videoId")
            if not video_id:
                continue

            original_categories = video.get("matchedCategories")
            original_game = video.get("game")
            original_keywords = set(video.get("matchedKeywords", []))

            video_type = video.get("type", "")
            title = video.get("title", "")

            type_for_setting = type_map.get(video_type, video_type)

            # é‡æ–°å¥—ç”¨åˆ†é¡é‚è¼¯
            result = match_category_and_game(title, type_for_setting, settings)
            new_categories = result.get("matchedCategories")
            new_game = result.get("game")
            new_keywords = set(result.get("matchedKeywords", []))

            if (
                new_categories != original_categories or
                new_game != original_game or
                original_keywords != new_keywords
            ):
                video_ref = videos_ref.document(video_id)
                video_ref.update({
                    "matchedCategories": new_categories,
                    "game": new_game,
                    "matchedKeywords": list(new_keywords)
                })
                updated_count += 1

        logging.info(f"âœ… [apply_category_settings_to_videos] æ›´æ–°å®Œæˆï¼Œå…±æ›´æ–° {updated_count} ç­†å½±ç‰‡")
        return updated_count

    except Exception:
        logging.exception("ğŸ”¥ [apply_category_settings_to_videos] æ›´æ–°åˆ†é¡æ™‚ç™¼ç”ŸéŒ¯èª¤")
        return 0