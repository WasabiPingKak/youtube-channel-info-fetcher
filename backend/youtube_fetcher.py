import os
import datetime
import pytz
import isodate
import googleapiclient.discovery
import googleapiclient.errors

API_KEY = os.getenv("API_KEY")
INPUT_CHANNEL = os.getenv("INPUT_CHANNEL")

# ğŸ¥ è¨­å®š API æœå‹™
def get_youtube_service():
    return googleapiclient.discovery.build("youtube", "v3", developerKey=API_KEY)


# ğŸ¥ æ ¹æ“š @å¸³è™Ÿ æˆ– channelId å‚³å›æ­£ç¢ºçš„ channelId
def get_channel_id(youtube, input_channel):
    if input_channel.startswith("UC"):
        return input_channel
    # Will increase API query, NOT recommend
    if input_channel.startswith("@"):
        username = input_channel[1:]
    else:
        username = input_channel

    try:
        response = youtube.search().list(part="snippet", q=username, type="channel", maxResults=1).execute()
        if response["items"]:
            return response["items"][0]["snippet"]["channelId"]
        else:
            print("âŒ æ‰¾ä¸åˆ°é »é“")
            return None
    except googleapiclient.errors.HttpError as err:
        print(f"HTTP Error: {err}")
        return None


# ğŸ¥ å–å¾—é »é“ä¸Šå‚³å½±ç‰‡æ¸…å–® ID
def get_uploads_playlist_id(youtube, channel_id):
    try:
        response = youtube.channels().list(part="contentDetails", id=channel_id).execute()
        return response['items'][0]['contentDetails']['relatedPlaylists']['uploads']
    except Exception as e:
        print(f"Error getting uploads playlist: {e}")
        return None


# ğŸ¥ å–å¾—æ’­æ”¾æ¸…å–®ä¸­æ‰€æœ‰å½±ç‰‡ ID
def get_video_ids_from_playlist(youtube, playlist_id):
    video_ids = []
    next_page_token = None
    while True:
        request = youtube.playlistItems().list(
            part='contentDetails',
            playlistId=playlist_id,
            maxResults=50,
            pageToken=next_page_token
        )
        response = request.execute()
        video_ids += [item['contentDetails']['videoId'] for item in response['items']]
        next_page_token = response.get('nextPageToken')
        if not next_page_token:
            break
    return video_ids


# ğŸ¥ æ‰¹æ¬¡å–å¾—å½±ç‰‡è©³ç´°è³‡æ–™
def fetch_video_details(youtube, video_ids):
    video_details = []
    for i in range(0, len(video_ids), 50):
        batch = video_ids[i:i + 50]
        try:
            response = youtube.videos().list(
                part='snippet,contentDetails,liveStreamingDetails',
                id=','.join(batch)
            ).execute()
            video_details.extend(response['items'])
        except Exception as e:
            print(f"Error fetching video details: {e}")
    return video_details


# ğŸ¥ è½‰æ›å½±ç‰‡é•·åº¦ç‚º HH:MM:SS ä¸¦å–å¾—ç¸½åˆ†é˜æ•¸
def convert_duration_to_hms(duration):
    parsed = isodate.parse_duration(duration)
    total_seconds = int(parsed.total_seconds())
    hours = total_seconds // 3600
    minutes = (total_seconds % 3600) // 60
    seconds = total_seconds % 60
    total_minutes = (hours * 60) + minutes + (seconds / 60)
    total_minutes = round(total_minutes, 1) if total_minutes < 1 else int(total_minutes)
    return f"{hours:02}:{minutes:02}:{seconds:02}", total_minutes


# ğŸ¥ å–å¾—ç™¼å¸ƒæ—¥æœŸèˆ‡æ˜ŸæœŸ
def get_video_publish_date(video):
    dt = datetime.datetime.fromisoformat(video['snippet']['publishedAt'][:-1])
    local_dt = dt.astimezone(pytz.timezone("Asia/Taipei"))
    #weekdays = ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'æ—¥']
    #return local_dt.strftime(f"%Y/%m/%d ({weekdays[local_dt.weekday()]})")
    return local_dt.strftime(f"%Y/%m/%d")


# ğŸ¥ åˆ¤æ–·å½±ç‰‡é¡å‹ï¼šå½±ç‰‡ã€Shorts æˆ–ç›´æ’­æª”
def get_video_type(video):
    if 'liveStreamingDetails' in video and 'actualEndTime' in video['liveStreamingDetails']:
        return "ç›´æ’­æª”"
    if video['snippet'].get('liveBroadcastContent') == 'upcoming':
        return None
    duration_minutes = convert_duration_to_hms(video['contentDetails']['duration'])[1]
    if duration_minutes <= 1:
        return "Shorts"
    return "å½±ç‰‡"


# æ–°å¢é€™å€‹å‡½å¼ï¼ŒæŠŠ main() çš„é‚è¼¯åŒ…é€²ä¾†
def get_video_data(date_ranges=None):
    youtube = get_youtube_service()
    channel_id = get_channel_id(youtube, INPUT_CHANNEL)
    playlist_id = get_uploads_playlist_id(youtube, channel_id)
    video_ids = get_video_ids_from_playlist(youtube, playlist_id)
    all_videos = fetch_video_details(youtube, video_ids)

    results = []
    for video in all_videos:
        video_type = get_video_type(video)
        if not video_type:
            continue

        published_dt = datetime.datetime.fromisoformat(video['snippet']['publishedAt'][:-1]).astimezone(pytz.timezone("Asia/Taipei"))
        if date_ranges and not any(start <= published_dt < end for start, end in date_ranges):
            continue

        duration_text, total_minutes = convert_duration_to_hms(video['contentDetails']['duration'])
        title = video['snippet']['title']
        video_id = video['id']
        date_text = get_video_publish_date(video)

        category = None
        if "ã€" in title and "ã€‘" in title:
            category = title.split("ã€")[1].split("ã€‘")[0]

        results.append({
            "æ¨™é¡Œ": title,
            "å½±ç‰‡ID": video_id,
            "ç™¼å¸ƒæ—¥æœŸ": date_text,
            "å½±ç‰‡æ™‚é•·": duration_text,
            "ç¸½åˆ†é˜æ•¸": total_minutes,
            "é¡åˆ¥": category or "ç„¡",
            "å½±ç‰‡é¡å‹": video_type
        })

    return results  # ä¸å¯«æª”æ¡ˆï¼Œç›´æ¥å›å‚³è³‡æ–™