from flask import Flask, request, jsonify
from flask_cors import CORS
import firebase_admin
from firebase_admin import credentials, firestore
import logging
import os
import datetime
import pytz
from youtube_fetcher import get_video_data

# âœ… è¨­å®š loggingï¼Œæœƒè¼¸å‡ºåˆ° Cloud Run logs
logging.basicConfig(level=logging.INFO)

# âœ… åˆå§‹åŒ– Firebase Admin SDK
if not firebase_admin._apps:
    try:
        cred = credentials.Certificate("firebase-key.json")
        firebase_admin.initialize_app(cred)
        logging.info("âœ… Firebase Admin åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        logging.error("âŒ åˆå§‹åŒ– Firebase Admin å¤±æ•—", exc_info=True)

# âœ… å»ºç«‹ Firestore ç”¨æˆ¶ç«¯
try:
    db = firestore.client()
except Exception as e:
    logging.error("âŒ åˆå§‹åŒ– Firestore å®¢æˆ¶ç«¯å¤±æ•—", exc_info=True)

app = Flask(__name__)
CORS(app)

@app.route("/")
def index():
    return "âœ… YouTube API Service with Firestore Cache is running."

@app.route("/videos")
def videos():
    try:
        doc = db.collection("videos").document("latest").get()
        if doc.exists and "data" in doc.to_dict():
            return jsonify(doc.to_dict()["data"])
        else:
            logging.warning("âš ï¸ Firestore ç„¡å¿«å–è³‡æ–™æˆ–æ ¼å¼éŒ¯èª¤")
            return jsonify([])
    except Exception as e:
        logging.error("ğŸ”¥ /videos ç™¼ç”Ÿä¾‹å¤–éŒ¯èª¤", exc_info=True)
        return jsonify({"error": "Internal Server Error"}), 500

@app.route("/refresh-cache")
def refresh_cache():
    try:
        start = request.args.get("start")
        end = request.args.get("end")

        tz = pytz.timezone("Asia/Taipei")
        date_ranges = None
        if start and end:
            try:
                start_dt = tz.localize(datetime.datetime.strptime(start, "%Y-%m-%d"))
                end_dt = tz.localize(datetime.datetime.strptime(end, "%Y-%m-%d"))
                date_ranges = [(start_dt, end_dt)]
                logging.info(f"ğŸ“† ä½¿ç”¨å‰ç«¯æŒ‡å®šæ—¥æœŸç¯„åœï¼š{start} ~ {end}")
            except Exception as e:
                logging.warning(f"âŒ æ—¥æœŸæ ¼å¼éŒ¯èª¤ï¼š{e}")

        # ğŸ”¹ å–å¾—æ–°çš„å½±ç‰‡è³‡æ–™
        new_data = get_video_data(date_ranges=date_ranges)

        # ğŸ”¹ å–å¾—èˆŠçš„å¿«å–è³‡æ–™
        old_doc = db.collection("videos").document("latest").get()
        old_data = old_doc.to_dict().get("data", []) if old_doc.exists else []

        # ğŸ”¹ åˆä½µå»é‡ï¼ˆä¾ videoIdï¼‰
        combined = {v["videoId"]: v for v in old_data}
        for item in new_data:
            combined[item["videoId"]] = item  # æ–°çš„æœƒè¦†è“‹èˆŠçš„ï¼ˆæˆ–æ–°å¢ï¼‰

        merged_data = list(combined.values())
        db.collection("videos").document("latest").set({"data": merged_data})

        logging.info(f"âœ… å¿«å–å·²åˆä½µæ›´æ–°ï¼Œç¸½å…± {len(merged_data)} ç­†ï¼ˆæ–°å¢ {len(new_data)} ç­†ï¼‰")
        return jsonify({
            "message": "âœ… å¿«å–å·²åˆä½µæ›´æ–°",
            "total": len(merged_data),
            "new_added": len(new_data)
        })

    except Exception as e:
        logging.error("ğŸ”¥ /refresh-cache ç™¼ç”Ÿä¾‹å¤–éŒ¯èª¤", exc_info=True)
        return jsonify({"error": "Internal Server Error"}), 500

@app.route("/api/cache/overwrite", methods=["POST"])
def overwrite_cache():
    try:
        data = request.get_json()
        start = data.get("start")
        end = data.get("end")

        if not start or not end:
            return jsonify({"error": "è«‹æä¾› start èˆ‡ end æ—¥æœŸ"}), 400

        tz = pytz.timezone("Asia/Taipei")
        try:
            start_dt = tz.localize(datetime.datetime.strptime(start, "%Y-%m-%d"))
            end_dt = tz.localize(datetime.datetime.strptime(end, "%Y-%m-%d"))
            date_ranges = [(start_dt, end_dt)]
            logging.info(f"ğŸ§¨ å¼·åˆ¶å¿«å–è¦†å¯«ï¼š{start} ~ {end}")
        except Exception as e:
            logging.warning(f"âŒ æ—¥æœŸæ ¼å¼éŒ¯èª¤ï¼š{e}")
            return jsonify({"error": "æ—¥æœŸæ ¼å¼éŒ¯èª¤ï¼Œè«‹ä½¿ç”¨ YYYY-MM-DD"}), 400

        # å–å¾—æ–°è³‡æ–™ä¸¦ç›´æ¥è¦†å¯«
        new_data = get_video_data(date_ranges=date_ranges)
        db.collection("videos").document("latest").set({"data": new_data})

        logging.info(f"ğŸ§¨ å¿«å–å·²è¦†å¯«ï¼Œå…± {len(new_data)} ç­†")
        return jsonify({
            "message": "ğŸ§¨ å¿«å–å·²å¼·åˆ¶è¦†å¯«",
            "count": len(new_data)
        })

    except Exception as e:
        logging.error("ğŸ”¥ /api/cache/overwrite ç™¼ç”Ÿä¾‹å¤–éŒ¯èª¤", exc_info=True)
        return jsonify({"error": "Internal Server Error"}), 500

# ğŸ”¹ GET: å–å¾—æ‰€æœ‰åˆ†é¡
@app.route("/api/categories", methods=["GET"])
def get_categories():
    categories_ref = db.collection("categories").stream()
    categories = [{"id": cat.id, **cat.to_dict()} for cat in categories_ref]
    return jsonify(categories)

# ğŸ” POST: åŒæ­¥åˆ†é¡èˆ‡é—œéµå­—ï¼ˆæ”¯æ´ sync èˆ‡ replace æ¨¡å¼ï¼‰
@app.route("/api/categories/sync", methods=["POST"])
def sync_categories():
    incoming_data = request.get_json()
    if not isinstance(incoming_data, list):
        return jsonify({"error": "è«‹å‚³å…¥åˆ†é¡é™£åˆ—"}), 400

    for item in incoming_data:
        name = item.get("name")
        keywords = item.get("keywords", [])
        mode = item.get("mode", "sync")  # é è¨­ç‚º sync æ¨¡å¼

        if not name or not isinstance(keywords, list):
            continue  # è·³éä¸åˆæ³•è³‡æ–™

        existing = db.collection("categories").where("name", "==", name).get()
        if existing:
            doc = existing[0]
            if mode == "replace":
                db.collection("categories").document(doc.id).update({
                    "keywords": keywords
                })
            else:  # sync æ¨¡å¼
                data = doc.to_dict()
                current_keywords = set(data.get("keywords", []))
                new_keywords = set(keywords)
                merged_keywords = list(current_keywords.union(new_keywords))

                if merged_keywords != current_keywords:
                    db.collection("categories").document(doc.id).update({
                        "keywords": merged_keywords
                    })
        else:
            db.collection("categories").add({
                "name": name,
                "keywords": keywords
            })

    return jsonify({"message": "åŒæ­¥å®Œæˆ"}), 200

# ğŸ§  è‡ªå‹•åˆ†é¡å½±ç‰‡æ¨™é¡Œï¼ˆæ ¹æ“šåˆ†é¡é—œéµå­—ï¼‰
def categorize_title_by_keywords(title):
    categories_ref = db.collection("categories").stream()
    matched = []

    for doc in categories_ref:
        cat = doc.to_dict()
        name = cat.get("name")
        keywords = cat.get("keywords", [])
        for kw in keywords:
            if kw in title:
                matched.append(name)
                break

    return matched

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8080))
    logging.info(f"âœ… Flask app is starting on port {port}...")
    app.run(host="0.0.0.0", port=port)