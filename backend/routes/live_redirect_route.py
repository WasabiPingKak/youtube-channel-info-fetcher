import logging
from flask import Blueprint, request, jsonify
from google.cloud.firestore import Client
from datetime import datetime, timedelta, timezone
from services.live_redirect.cache_builder import build_live_redirect_cache_entries

live_redirect_bp = Blueprint("live_redirect", __name__)

CACHE_TTL_MINUTES = 15

def init_live_redirect_route(app, db: Client):
    @live_redirect_bp.route("/api/live-redirect/cache", methods=["GET"])
    def get_live_redirect_cache():
        try:
            force = request.args.get("force", "false").lower() == "true"
            now = datetime.now(timezone.utc)
            today_str = now.date().isoformat()
            yesterday_str = (now - timedelta(days=1)).date().isoformat()

            # ğŸ”¸ å¿«å–æ–‡ä»¶åƒè€ƒ
            today_cache_ref = db.collection("live_redirect_cache").document(today_str)
            today_cache = today_cache_ref.get().to_dict() or {}

            # â³ è‹¥éå¼·åˆ¶æ›´æ–°ä¸”å¿«å–æœªéæœŸï¼Œç›´æ¥å›å‚³
            updated_at = today_cache.get("updatedAt")
            if not force and updated_at:
                updated_time = datetime.fromisoformat(updated_at)
                if now - updated_time < timedelta(minutes=CACHE_TTL_MINUTES):
                    logging.info("â™»ï¸ å¿«å–æœªéæœŸï¼Œç›´æ¥å›å‚³")
                    return jsonify(today_cache)

            # ğŸ“¥ è®€å–æ˜¨å¤©èˆ‡ä»Šå¤©çš„é€šçŸ¥ä½‡åˆ—
            queue_docs = {
                date_str: db.collection("live_redirect_notify_queue").document(date_str).get().to_dict() or {}
                for date_str in [yesterday_str, today_str]
            }

            # åˆä½µ videosï¼Œå¾Œå‡ºç¾è€…è¦†è“‹
            all_videos_map = {}
            for data in queue_docs.values():
                for v in data.get("videos", []):
                    video_id = v.get("videoId")
                    if video_id:
                        all_videos_map[video_id] = v
            videos = list(all_videos_map.values())

            # ğŸ” ç¬¬ä¸€æ¬¡è™•ç†ï¼šbuild å¿«å–è³‡æ–™ï¼ˆåƒ…è™•ç†æœªè™•ç†çš„å½±ç‰‡ï¼‰
            new_channels, processed_video_ids = build_live_redirect_cache_entries(
                videos, db, now,
                skip_if_processed=True,
                update_endtime_only=False
            )

            # åˆä½µèˆŠæœ‰å¿«å–ï¼ˆåŒä¸€å½±ç‰‡ä»¥æ–°è³‡æ–™ç‚ºæº–ï¼‰
            existing_map = {c["live"]["videoId"]: c for c in today_cache.get("channels", [])}
            for c in new_channels:
                existing_map[c["live"]["videoId"]] = c
            merged_channels = list(existing_map.values())

            # ğŸ”„ å¯«å…¥ä»Šæ—¥å¿«å–
            today_cache_ref.set({
                "updatedAt": now.isoformat(),
                "channels": merged_channels
            })

            # ğŸ“ å›å¯« processedAt è‡³æ˜¨å¤©èˆ‡ä»Šå¤©çš„ queue
            for date_str, data in queue_docs.items():
                new_list = []
                for v in data.get("videos", []):
                    if v.get("videoId") in processed_video_ids:
                        v["processedAt"] = now.isoformat()
                    new_list.append(v)
                db.collection("live_redirect_notify_queue").document(date_str).set({
                    "updatedAt": now.isoformat(),
                    "videos": new_list
                })

            # ğŸ§¼ æ‡¶æ›´æ–°ï¼šè™•ç† endTime ç‚º null çš„å¿«å–
            needs_update = [c for c in merged_channels if not c["live"].get("endTime")]
            updated_channels, _ = build_live_redirect_cache_entries(
                needs_update, db, now,
                skip_if_processed=False,
                update_endtime_only=True
            )
            for c in updated_channels:
                merged_video_id = c["live"]["videoId"]
                for i, existing in enumerate(merged_channels):
                    if existing["live"]["videoId"] == merged_video_id:
                        merged_channels[i] = c
                        break

            # ğŸ”„ åˆä½µæ˜¨å¤©å¿«å–çš„å°šæœªæ”¶æ’­å½±ç‰‡
            yesterday_cache = db.collection("live_redirect_cache").document(yesterday_str).get().to_dict() or {}
            for c in yesterday_cache.get("channels", []):
                vid = c["live"]["videoId"]
                if vid not in {v["live"]["videoId"] for v in merged_channels}:
                    if not c["live"].get("endTime"):
                        merged_channels.append(c)

            logging.info(f"âœ… å¿«å–é‡å»ºå®Œæˆï¼Œchannels={len(merged_channels)}ï¼Œæ›´æ–°å½±ç‰‡={len(processed_video_ids)}")

            return jsonify({
                "updatedAt": now.isoformat(),
                "channels": merged_channels
            })

        except Exception:
            logging.exception("ğŸ”¥ å¿«å–é‡å»ºæµç¨‹å¤±æ•—")
            return jsonify({"error": "Internal Server Error"}), 500

    app.register_blueprint(live_redirect_bp)
